# 聚类

## 第9章 聚类

* Page197: 有效性指标

  聚类性能度量，即评估其好坏的性能度量。聚类性能度量分为两类，外部指标和内部指标。

* Page199: 距离度量

  用于衡量点和点之间的距离，常用的有欧氏、曼哈顿、切比雪夫。最常用的是闵可夫斯基距离：  
  $$dist_{mk}(x_i,x_j)={\left( \sum_{u=1}^{n}\left|x_{iu}-x_{ju} \right|^p\right)}^{\frac{1}{p}}$$

* Page200: 街区距离

  闵可夫斯基距离$$p=1$$时即曼哈顿距离，又称街区距离: $$dist_{man}(x_i,x_j)={\parallel x_i-x_j\parallel }_{1} =\sum_{u=1}^{n}\left|x_{iu}-x_{ju} \right|$$

* Page200: 离散属性

  定义域上有限个取值，比如{西瓜，哈密瓜，木瓜}。

* Page200: 连续属性

  定义域上可以取无限个取值，如实数。

* Page200: 列名属性

  “离散属性”也称“列名属性”，见“离散属性”。

* Page200: 曼哈顿距离

  同“街区距离”。

* Page200: 闵可夫斯基距离\(220\)

  见“距离度量”。

* Page200: 欧氏距离

  闵可夫斯基距离$$p=2$$时即欧氏距离：  
  $$dist_{ed}(x_i,x_j)={\parallel x_i-x_j\parallel }_{2} =\sqrt{\sum_{u=1}^{n}\left|x_{iu}-x_{ju} \right|^2}$$

* Page200: 切比雪夫距离

  闵可夫斯基距离当$$p\rightarrow \infty$$时即切比雪夫距离。

* Page200: 数值属性

  见“连续属性”。

* Page200: 无序属性

  不能直接在属性值上计算距离。

* Page200: 有序属性

  可以直接在属性值上计算距离。

* Page201: 非度量距离

  不满足直递性的距离。

* Page201: 混合属性

  存在有序属性和无序属性。

* Page201: 加权距离

  即给每个距离加权重。

* Page201: 相似度度量

  对两个事物之间相似程度的综合性度量。

* Page201: 距离度量学习\(237\)

  度量学习（Metric Learning）是常说的相似度学习，距离度量学习则是选定距离计算式来进行度量。

* Page202: 原型聚类

  基于原型的聚类，著名的几种方法包括k均值算法、学习向量量化和高斯混合聚类等。

* Page202: k均值算法\(218\)

  针对聚类所得的簇，同类样本的最小均方误差。

* Page204: LVQ\(218\)

  见下

* Page204: 学习向量化\(Learning Vector Quantization, LVQ\)

  指通过找到一组原型向量来刻画聚类结构，每个原型向量代表一个聚类簇。

* Page206: 概率模型\(319\)

  概率模型是将学习归结为计算变量的概率分布的一种描述。

* Page206: 高斯混合\(296\)

  高斯混合是用高斯概率密度函数去量化，将变量/事物分解为若干个高斯密度函数的模型。

* Page211: 密度聚类

  基于密度的聚类，即是通过事物的紧密程度去聚类。如DBSCAN算法。

* Page214: 层次聚类

  通过不同层次对数据集进行划分，得到的是树形聚类结构。可采用“自顶向下”的分拆策略，也可用“自底向上”的聚合策略。著名的AGNES是自底向上聚合的层次聚类算法。

* Page219: 聚类集成

  对原始数据集的多个聚类器进行集成。可有效降低聚类过程中的随机性和聚类假设不符等因素的影响。

* Page219: 异常检测

  异常检测常借助聚类或距离计算，如将离心或密度极低的点作为异常点。

* Page220: 豪斯多夫距离

  Hausdorff distance： $$dist_H(X, Z) = \max (dist_h(X, Z), dist_h(Z, X))$$ 其中 $$dist_h(X, Z) = \max \limits_{x\in X} \min \limits_{z\in Z}\left \| x-z \right \|_2$$

